{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_61O20AmyovN",
    "outputId": "dcd44746-c1c2-493d-e7d0-0eb81636f2b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!ls '/content/drive/MyDrive/mami_data'\n",
    "\n",
    "# import zipfile\n",
    " \n",
    "# zip_file = \"/content/drive/MyDrive/mami_data/training.zip\"\n",
    " \n",
    "# try:\n",
    "#     with zipfile.ZipFile(zip_file) as z:\n",
    "#         z.extractall(\"/content/drive/MyDrive/mami_data/training\")\n",
    "#         print(\"Extracted all\")\n",
    "# except:\n",
    "#     print(\"Invalid file\")\n",
    "\n",
    "!ls '/content/drive/MyDrive/mami_data/training/TRAINING/training.csv'\n",
    "\n",
    "# import zipfile\n",
    " \n",
    "# zip_file = \"/content/drive/MyDrive/mami_data/trial.zip\"\n",
    " \n",
    "# try:\n",
    "#     with zipfile.ZipFile(zip_file) as z:\n",
    "#         z.setpassword(pwd = bytes('*MaMiSemEval2022!', 'utf-8'))\n",
    "#         z.extractall(\"/content/drive/MyDrive/mami_data/trial\")\n",
    "#         print(\"Extracted all\")\n",
    "# except:\n",
    "#     print(\"Invalid file\")\n",
    "\n",
    "!ls '/content/drive/MyDrive/mami_data/trial/Users/fersiniel/Desktop/MAMI - TO LABEL/TRIAL DATASET'\n",
    "\n",
    "#import zipfile\n",
    " \n",
    "#zip_file = \"/content/drive/MyDrive/mami_data/test.zip\"\n",
    " \n",
    "#try:\n",
    "#   with zipfile.ZipFile(zip_file) as z:\n",
    "#       z.setpassword(pwd = bytes('*MaMiSemEval2022!', 'utf-8'))\n",
    "#        z.extractall(\"/content/drive/MyDrive/mami_data/test\")\n",
    "#        print(\"Extracted all\")\n",
    "#except:\n",
    "#    print(\"Invalid file\")\n",
    "\n",
    "!ls '/content/drive/MyDrive/mami_data/test/test/Test.csv'\n",
    "\n",
    "#!cp '/content/drive/MyDrive/mami_data/trial/Users/fersiniel/Desktop/MAMI - TO LABEL/TEST DATASET/test.csv' '/content/drive/MyDrive/mami_data/test'\n",
    "\n",
    "!cp '/content/drive/MyDrive/mami_data/trial/Users/fersiniel/Desktop/MAMI - TO LABEL/TRIAL DATASET/trial.csv' '/content/drive/MyDrive/mami_data/trial'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "applying preprocessing with cleaningg tokenizing and lematization\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "data1=pd.read_csv('/content/drive/MyDrive/mami_data/training/TRAINING/training.csv', sep='\\t')\n",
    "data2=pd.read_csv(\"/content/drive/MyDrive/mami_data/trial/trial.csv\",sep='\\t')\n",
    "#training_label=data['misogynous']\n",
    "# print(training_data.head())\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stop_words=stopwords.words('english')\n",
    "stop_words.append('imgflipcom')\n",
    "stop_words.append('zip')\n",
    "print(stop_words)\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "#training data\n",
    "for index,row in data1.iterrows():\n",
    "  #print(row)\n",
    "  filter_sentence=[]\n",
    "  sentence=row['Text Transcription']\n",
    "  sentence = sentence.lower()\n",
    "  #print(sentence)\n",
    "  sentence=re.sub(r'[^\\w\\s]','',sentence)#cleaning\n",
    "  words=nltk.word_tokenize(sentence)\n",
    "  words=[w for w in words if not w in stop_words]\n",
    "  for word in words:\n",
    "    filter_sentence.append(lemmatizer.lemmatize(word))\n",
    "  #print(filter_sentence)\n",
    "  listToStr = ' '.join([str(elem) for elem in filter_sentence])\n",
    "  data1.loc[index,\"Text Transcription\"]=listToStr\n",
    "#trail data\n",
    "for index,row in data2.iterrows():\n",
    "  #print(row)\n",
    "    filter_sentence=[]\n",
    "    sentence=row['Text Transcription']\n",
    "    sentence = sentence.lower()\n",
    "    #print(sentence)\n",
    "    sentence=re.sub(r'[^\\w\\s]','',sentence)#cleaning\n",
    "    words=nltk.word_tokenize(sentence)\n",
    "    words=[w for w in words if not w in stop_words]\n",
    "    for word in words:\n",
    "        filter_sentence.append(lemmatizer.lemmatize(word))\n",
    "    #print(filter_sentence)\n",
    "    listToStr = ' '.join([str(elem) for elem in filter_sentence])\n",
    "    data2.loc[index,\"Text Transcription\"]=listToStr\n",
    "print(data1.head())\n",
    "print(data1.shape)\n",
    "print(data2.head())\n",
    "print(data2.shape)\n",
    "#data=pd.concat([data1,data2])\n",
    "#print(data.head())\n",
    "#print(data.shape)\n",
    "\n",
    "applying countvectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "training_data=data1['Text Transcription']\n",
    "training_label=data1['misogynous']\n",
    "X_train_counts = count_vect.fit_transform(training_data)\n",
    "X_train_counts.shape\n",
    "\n",
    "\n",
    "TF-IDF transormer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape\n",
    "print(X_train_tfidf)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "clf = LogisticRegressionCV().fit(X_train_tfidf, training_label)\n",
    "docs_new = [\"IT'S SUPER RARE TO FIND A'KITCHEN THAT HAS FOUR OVENS AND THREE DISHWASHERS -SB \"]\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "print(predicted)\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "sns.countplot(training_label)\n",
    "text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf',KNeighborsClassifier(n_neighbors=5)),\n",
    " ])\n",
    "scores=cross_val_score(text_clf,training_data,training_label,cv=10,scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "\n",
    "To find best parameter \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "k_range=range(1,50)\n",
    "k_scores=[]\n",
    "for k in k_range:\n",
    "  text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf',KNeighborsClassifier(n_neighbors=k)),\n",
    "      ])\n",
    "  scores=cross_val_score(text_clf,training_data,training_label,cv=10,scoring='accuracy')\n",
    "  k_scores.append(scores.mean())\n",
    "print(k_scores)\n",
    "plt.plot(k_range,k_scores)\n",
    "plt.xlabel('Value of k for KNN')\n",
    "plt.ylabel('Cross Validated accuracy')\n",
    "\n",
    "\n",
    "tuning hyper parameter using grid search cv\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "k_range=range(1,50)\n",
    "print(k_range)\n",
    "param_grid=dict(n_neighbors=k_range)\n",
    "print(param_grid)\n",
    "knn=KNeighborsClassifier( )\n",
    "grid=GridSearchCV(knn,param_grid,cv=10,scoring='accuracy',n_jobs=-1)\n",
    "grid.fit(X_train_tfidf,training_label)\n",
    "#grid.grid_scores_\n",
    "grid.cv_results_\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "for mean,param in zip(means,params):\n",
    "    print(\"%f  with:   %r\" % (mean,param))\n",
    "grid.mean_scores=means\n",
    "\n",
    "plt.plot(k_range,grid.mean_scores)\n",
    "plt.xlabel('Value of k for KNN')\n",
    "plt.ylabel('Cross Validated accuracy')\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "#testing accuracy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_train_tfidf,training_label, test_size=0.2, random_state=4)\n",
    "X_train=X_train_tfidf\n",
    "X_test=training_label\n",
    "y_train=data2['Text Transcription']\n",
    "y_test=data2['misogynous']\n",
    "text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', KNeighborsClassifier(n_neighbors=44)),\n",
    " ])\n",
    "knn=KNeighborsClassifier(n_neighbors=44)\n",
    "text_clf.fit(training_data, training_label)\n",
    "y_pred = text_clf.predict(y_train)\n",
    "metrics.accuracy_score(y_test,y_pred)\n",
    "metrics.confusion_matrix(y_test, y_pred)\n",
    "print(metrics.classification_report(y_test,y_pred\n",
    "     ))\n",
    "\n",
    "#validation accuracy for training data\n",
    "knn=KNeighborsClassifier(n_neighbors=44)\n",
    "scores=cross_val_score(knn,X_train_tfidf,training_label,cv=10,scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "\n",
    "text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', KNeighborsClassifier(n_neighbors=45)),\n",
    " ])\n",
    "text_clf.fit(training_data, training_label)\n",
    "test_data=pd.read_csv(\"/content/drive/MyDrive/mami_data/test/test/Test.csv\",sep='\\t')\n",
    "testing_data=test_data['Text Transcription']\n",
    "predictednew = text_clf.predict(testing_data)\n",
    "print(predictednew)\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!unzip /content/drive/MyDrive/mami_data/train_pixel1.zip\n",
    "\n",
    "\n",
    "#!ls /content/drive/MyDrive/mami_data/training/TRAINING/\n",
    "\n",
    "#!unzip -P *MaMiSemEval2022! /content/drive/MyDrive/mami_data/training/TRAINING/trial.zip\n",
    "\n",
    "\n",
    "# !unzip -P *MaMiSemEval2022! /content/drive/MyDrive/mami_data/training/TRAINING/test.zip\n",
    "\n",
    "first creating csv file with feature extraction from images and reading csv file\n",
    "\n",
    "#import glob\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "from keras.preprocessing.image import img_to_array,array_to_img,load_img\n",
    "train_image = pd.read_csv('train_pixel1.csv')\n",
    "print(train_image.shape)\n",
    "test_image = pd.read_csv('/content/drive/MyDrive/mami_data/test_pixel.csv')\n",
    "print(test_image.shape)\n",
    "\n",
    "\n",
    "#reading training and testing datasets\n",
    "import pandas as pd\n",
    "total_data_train=pd.read_csv('/content/drive/MyDrive/mami_data/training/TRAINING/training.csv',sep='\\t')\n",
    "total_data_test=pd.read_csv('/content/drive/MyDrive/mami_data/trial/trial.csv',sep='\\t')\n",
    "print(total_data_train['file_name'])\n",
    "\n",
    "#y_train is extracting from training dataset by checking filename and file_list\n",
    "import os\n",
    "file_list=os.listdir(r\"/content/drive/MyDrive/mami_data/training/TRAINING/training2_data/training/\")\n",
    "#print(file_list)\n",
    "y_train=[]\n",
    "for j in range(0,2001): \n",
    "  for i in range(len(total_data_train)):\n",
    "      if(file_list[j]==(total_data_train['file_name'][i])):\n",
    "        y_train.append(total_data_train['misogynous'][i])\n",
    "      else:\n",
    "        continue\n",
    "print(len(y_train))\n",
    "\n",
    "#y_test is extracting from training dataset by checking filename and file_list\n",
    "file_list2=os.listdir(r\"/content/drive/MyDrive/mami_data/trial/Users/fersiniel/Desktop/MAMI - TO LABEL/TRIAL DATASET/\")\n",
    "y_test=[]\n",
    "for j in file_list2: \n",
    "  for i in range(len(total_data_test)):\n",
    "      if(j==(total_data_test['file_name'][i])):\n",
    "        y_test.append(total_data_test['misogynous'][i])\n",
    "      else:\n",
    "        continue\n",
    "\n",
    "X_train=train_image#train_image is a feature extraction from image dataset\n",
    "X_test=test_image#train_image is a feature extraction from image dataset\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "KNN algorithm is applied to model\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "sns.countplot(y_train)\n",
    "clf=KNeighborsClassifier()\n",
    "scores=cross_val_score(clf,X_train,y_train,cv=5,scoring='accuracy')\n",
    "print(scores)\n",
    "print(len(X_train))\n",
    "print(scores.mean())\n",
    "\n",
    "\n",
    "To find best parameter \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "k_range=range(1,20)\n",
    "k_scores=[]\n",
    "for k in k_range:\n",
    "     clf=KNeighborsClassifier(n_neighbors=k)\n",
    "     scores=cross_val_score(clf,X_train,y_train,cv=5,scoring='accuracy')\n",
    "     k_scores.append(scores.mean())\n",
    "print(k_scores)\n",
    "plt.plot(k_range,k_scores)\n",
    "plt.xlabel('Value of k for KNN')\n",
    "plt.ylabel('Cross Validated accuracy')\n",
    "\n",
    "\n",
    "tuning hyper parameter using grid search cv\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "k_range=range(1,20)\n",
    "print(k_range)\n",
    "param_grid=dict(n_neighbors=k_range)\n",
    "print(param_grid)\n",
    "knn=KNeighborsClassifier( )\n",
    "grid=GridSearchCV(knn,param_grid,cv=5,scoring='accuracy',n_jobs=-1)\n",
    "grid.fit(X_train,y_train)\n",
    "#grid.grid_scores_\n",
    "grid.cv_results_\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "#for mean,param in zip(means,params):\n",
    "#print(\"%f  with:   %r\" % (mean,param))\n",
    "grid.mean_scores=means\n",
    "\n",
    "plt.plot(k_range,grid.mean_scores)\n",
    "plt.xlabel('Value of k for KNN')\n",
    "plt.ylabel('Cross Validated accuracy')\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=2)\n",
    "scores=cross_val_score(knn,X_train,y_train,cv=5,scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "\n",
    "clf= KNeighborsClassifier(n_neighbors=2)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "mamiwithknn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
